{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f39c36b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dadapy import data\n",
    "import torchvision\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple\n",
    "import numpy as np\n",
    "from urllib.request import urlretrieve\n",
    "from os.path import exists, isdir\n",
    "from os import makedirs\n",
    "from math import ceil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5f63d8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x20e40a13f70>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75cc66da",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5865bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_kmnist(data_path = \"kmnist\", force_download = True, normalize = True):\n",
    "    \"\"\"Function that fetches the train and test kmnist dataset and returns it in a numpy array.\n",
    "    It downloads it if the file is not present or if force_download is True.\"\"\"\n",
    "    \n",
    "    url = 'http://codh.rois.ac.jp/kmnist/dataset/kmnist/kmnist-'\n",
    "    train_set_url = url + 'train-imgs.npz'\n",
    "    test_set_url  = url + 'test-imgs.npz'\n",
    "    train_labels_url = url + 'train-labels.npz'\n",
    "    test_labels_url  = url + 'test-labels.npz'\n",
    "    \n",
    "    train_set_path = data_path + \"/train_set\"\n",
    "    test_set_path  = data_path + \"/test_set\"\n",
    "    train_labels_path = data_path + \"/train_labels\"\n",
    "    test_labels_path = data_path + \"/test_labels\"\n",
    "    \n",
    "    if not isdir(data_path):\n",
    "        makedirs(data_path)\n",
    "    \n",
    "    for path,url in [(train_set_path,train_set_url),(test_set_path,test_set_url),(train_labels_path,train_labels_url),(test_labels_path,test_labels_url)]:\n",
    "        if not exists(path) or force_download:\n",
    "            print(f\"downloading data from {url} to {path}\")\n",
    "            urlretrieve(url, path)\n",
    "       \n",
    "    train_set = np.load(train_set_path)['arr_0'] / 255 if normalize else np.load(train_set_path)['arr_0']\n",
    "    test_set  = np.load(test_set_path)['arr_0'] / 255 if normalize else np.load(test_set_path)['arr_0']\n",
    "    train_labels = np.load(train_labels_path)['arr_0']\n",
    "    test_labels  = np.load(test_labels_path)['arr_0']\n",
    "    \n",
    "    return train_set, test_set, train_labels, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c7f1d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set, train_labels, test_labels = fetch_kmnist(force_download = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7bf3e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_loaders(batch_size = 256):\n",
    "    torch_train = torch.Tensor(train_set).view(-1, 1,28,28).float()\n",
    "    torch_test  = torch.Tensor(test_set).view(-1,1,28,28).float()\n",
    "\n",
    "    torch_train_set = TensorDataset(torch_train,torch.from_numpy(train_labels))\n",
    "    train_dataloader = DataLoader(torch_train_set, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    torch_test_set = TensorDataset(torch_test,torch.from_numpy(test_labels))\n",
    "    test_dataloader = DataLoader(torch_test_set, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    return train_dataloader,test_dataloader\n",
    "\n",
    "train_dataloader,test_dataloader = create_data_loaders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2aad096a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_id_with_twoNN(dataset):\n",
    "    _data = data.Data(dataset.reshape(-1,28*28))\n",
    "    # estimate ID\n",
    "    id_twoNN, _, r = _data.compute_id_2NN()\n",
    "    return ceil(id_twoNN)\n",
    "\n",
    "id_twoNN = compute_id_with_twoNN(train_set)\n",
    "#id_twoNN = 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2d08901",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AE(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels = 1, out_channels = 32, kernel_size = 3, stride = 1, padding = 0),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size = 2),\n",
    "            torch.nn.Conv2d(in_channels = 32, out_channels = 64, kernel_size = 3, stride = 2, padding = 1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size = 2, stride = 1),\n",
    "            torch.nn.Flatten(),\n",
    "            torch.nn.Linear(6*6*64, id_twoNN)\n",
    "        )\n",
    "    \n",
    "        self.decoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(id_twoNN, 64*8*8),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Unflatten(1, torch.Size([64, 8, 8])),\n",
    "            torch.nn.ConvTranspose2d(in_channels = 64, out_channels = 32, kernel_size = 2, stride = 2, padding = 1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.ConvTranspose2d(in_channels = 32, out_channels = 1, kernel_size = 2, stride = 2, padding = 0),\n",
    "            torch.nn.ReLU()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.encoder(x)\n",
    "        out = self.decoder(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da14e18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AE().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62129e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr = 1e-3)\n",
    "loss = torch.nn.MSELoss(reduction = 'sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a0eeee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training loss:52.04151257324219\n",
      "Epoch 2 Training loss:34.643281766764325\n",
      "Epoch 3 Training loss:31.750752897135417\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-3f9d96765032>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0ml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Epoch \"\u001b[0m\u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\" Training loss:\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loss\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    485\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    486\u001b[0m             )\n\u001b[1;32m--> 487\u001b[1;33m         torch.autograd.backward(\n\u001b[0m\u001b[0;32m    488\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    489\u001b[0m         )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     \u001b[1;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m     \u001b[1;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 197\u001b[1;33m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[0;32m    198\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for x,_ in iter(train_dataloader):\n",
    "        x=x.to(device)\n",
    "        x_hat = model(x)\n",
    "        l = loss(x_hat,x)\n",
    "        train_loss += l.item()\n",
    "        optimizer.zero_grad()\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "    print(\"Epoch \"+ str(epoch+1) + \" Training loss:\" + str(train_loss / (len(train_dataloader.dataset))))\n",
    "    \n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    test_loss=0 \n",
    "    for x,_ in iter(test_dataloader):\n",
    "            x=x.to(device)\n",
    "            x_hat=model(x)\n",
    "            l=loss(x_hat,x)\n",
    "            test_loss+=l.item()\n",
    "    test_loss /= len(test_dataloader.dataset)\n",
    "    print(\"Test set loss:\"+str(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b8544f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_images(input, output):\n",
    "    if input is not None:\n",
    "        input_pics = input.data.cpu().numpy().transpose((0,2,3,1))\n",
    "        plt.figure(figsize=(18, 4))\n",
    "        for i in range(4):\n",
    "            plt.subplot(1,4,i+1)\n",
    "            plt.imshow(input_pics[i],cmap='gray')\n",
    "    plt.figure(figsize=(18, 4))\n",
    "    output_pics = output.data.cpu().numpy().transpose((0,2,3,1))\n",
    "    for i in range(4):\n",
    "        plt.subplot(1,4,i+1)\n",
    "        plt.imshow(output_pics[i],cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6c55fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_images(x,out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948b462e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = model.encoder\n",
    "        self.layer2 = torch.nn.Linear(in_features = id_twoNN, out_features = 10, bias = True)\n",
    "        self.activation = torch.nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.layer1(x))\n",
    "        x = self.layer2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eee1cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Classifier().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756ce9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name,param in classifier.named_parameters():\n",
    "    param.requires_grad = False if \"layer1\" in name else True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4eb736",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=torch.optim.Adam(filter(lambda p: p.requires_grad, classifier.parameters()), lr=1e-3)\n",
    "loss=torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48be8c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(model, dataloader):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct=0\n",
    "        for x, y in iter(dataloader):\n",
    "            x=x.to(device)\n",
    "            y=y.to(device)\n",
    "            out=model(x)\n",
    "            correct+=(torch.argmax(out, axis=1)==y).sum()\n",
    "        return round(float(correct/len(dataloader.dataset)),4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f74c18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=10\n",
    "losses=[]\n",
    "for epoch in range(epochs):\n",
    "    print(\"Test accuracy: \", get_accuracy(classifier, test_dataloader))\n",
    "    classifier.train()\n",
    "    print(\"Epoch: \", epoch)\n",
    "    for x, y in iter(train_dataloader):\n",
    "        x=x.to(device)\n",
    "        y=y.to(device)\n",
    "        out=classifier(x)\n",
    "        l=loss(out, y)\n",
    "        optimizer.zero_grad()\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(l.item())\n",
    "print(\"Final accuracy: \", get_accuracy(classifier, test_dataloader))\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"KMNIST batch loss\")\n",
    "plt.plot(losses)\n",
    "plt.xlabel(\"Optimization step\")\n",
    "_ = plt.ylabel(\"CE Loss\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
